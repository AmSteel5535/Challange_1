# -*- coding: utf-8 -*-
"""Cab_Fare_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mGEBUAxE9aMjfz1yInQrUc4j_KmLZY2a
"""

import pandas as pd
import matplotlib.pyplot as plt

from google.colab import drive 
drive.mount('/content/gdrive')

ds=pd.read_csv("gdrive/My Drive/TRAIN.csv")
ds.head(10)

print(ds.shape)
ds.dtypes

Y=pd.DataFrame(data=ds.iloc[:,8].values,columns=["target"])
ds=ds.drop(["index","fare"],axis=1)
ds.head()

#x=set(ds["cab_provider"])   ##{'Lyft', 'Uber'}
#x=set(ds["source"])   ## ------{'Back Bay','Beacon Hill','Boston University','Fenway','Financial District','Haymarket Square','North End','North Station','Northeastern University','South Station','Theatre District','West End'}
#x=set(ds["destination"])   ##{'Back Bay','Beacon Hill','Boston University','Fenway','Financial District','Haymarket Square','North End','North Station','Northeastern University',South Station','Theatre District','West End'}

#x=set(ds["cab_type"])
#x

from sklearn.preprocessing import LabelEncoder

ds["cab_provider"] = LabelEncoder().fit_transform(ds["cab_provider"])
ds["source"] = LabelEncoder().fit_transform(ds["source"])
ds["destination"] = LabelEncoder().fit_transform(ds["destination"])
ds["cab_type"] = LabelEncoder().fit_transform(ds["cab_type"])

ds.head()

ds["time_stamp"]=pd.to_datetime(ds["time_stamp"],unit="ms")
ds.head()

ds["time_stamp"] = LabelEncoder().fit_transform(ds["time_stamp"])
ds.head()

ds.describe()

# Heatmap
import numpy as np
import seaborn as sns
f, ax = plt.subplots(figsize=(10, 8))
corr = ds.corr()
sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),square=True, ax=ax,annot=True)
plt.show()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(ds,Y,test_size=.25,random_state=42)
x_train.info()

# Evaluation Metrics
from sklearn import metrics
def print_error(X_test, y_test, model_name):
    prediction = model_name.predict(X_test)
  #  print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, prediction))
  #  print('Mean Squared Error:', metrics.mean_squared_error(y_test, prediction))
    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))
  #  cm=metrics.confusion_matrix(y_test,prediction.round())
  #  sns.heatmap(cm,annot=True)
 #   plt.show()
  #  print("Accuracy of Model:",metrics.accuracy_score(y_test,prediction.round()))

from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import PowerTransformer
from sklearn.preprocessing import QuantileTransformer

import keras
from keras.layers import Dense

def model_scale(scler):
    if scler =="MinMaxScaler":
        x_train_n = MinMaxScaler().fit_transform(x_train)
        x_test_n = MinMaxScaler().fit_transform(x_test)
    elif scler == "StandardScaler":
        x_train_n = StandardScaler().fit_transform(x_train)
        x_test_n = StandardScaler().fit_transform(x_test)
    elif scler == "PowerTransformer":
        x_train_n = PowerTransformer(method='yeo-johnson').fit_transform(x_train)
        x_test_n = PowerTransformer(method='yeo-johnson').fit_transform(x_test)
    elif scler =="QuantileTransformer":
        x_train_n = QuantileTransformer(output_distribution='normal').fit_transform(x_train)
        x_test_n = QuantileTransformer(output_distribution='normal').fit_transform(x_test)
    
    """print("logistic regression model prediction error:\n")
    #by using logistic regression model
    from sklearn.linear_model import LogisticRegression
    log_m=LogisticRegression()
    log_m.fit(x_train_n,y_train)
    print_error(x_test_n,y_test,log_m)
    """
    print("linear regression model prediction error:\n")
    #by using linear regression model
    from sklearn import linear_model
    lrm=linear_model.LinearRegression()
    lrm.fit(x_train_n,y_train)
    print_error(x_test_n,y_test,lrm)
    """
    """

    print("\nSupport Vector Regressor Model prediction error:\n")
    #by using Support Vector Regressor
    from sklearn.svm import SVR
    Svrm=SVR()
    Svrm.fit(x_train_n,y_train)
    print_error(x_test_n,y_test,Svrm)
    """
    """

    print("\nDecision Tree Regressor Model prediction error:\n")
    #Decision Tree Regressor
    from sklearn.tree import DecisionTreeRegressor
    dtrm=DecisionTreeRegressor()
    dtrm.fit(x_train_n,y_train)
    print_error(x_test_n,y_test,dtrm)
    """
    """

    print("\nRandom Forest Regressor Model prediction error:\n")
    #
    # Random Forest Regressor
    from sklearn.ensemble import RandomForestRegressor
    n_estimators = 200
    max_depth = 25
    min_samples_split=15
    min_samples_leaf=2

    rfrm = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, min_samples_split=min_samples_split)
    rfrm.fit(x_train_n,y_train)
    print_error(x_test_n,y_test, rfrm)
    
    
    print("\nArtificial Neural Network Model prediction error:\n")
    #Artificial Neural Network by using Adam smith optimizer
    ann = keras.models.Sequential([Dense(8,activation="relu",
                                         input_shape=x_train_n.shape[1:]),
                                   Dense(8,activation="relu"),
                                   Dense(1)])
    optimizer=keras.optimizers.Adam()
    loss=keras.losses.mean_squared_error

    ann.compile(optimizer=optimizer,
                loss=loss,
                metrics=["mean_squared_error"])

    #..........

    history=ann.fit(x_train_n,y_train,epochs=150)
    ann.summary()
    print_error(x_test_n,y_test,ann)
    
   # print("Score of log_m",log_m.score(x_test_n,y_test))
    print("Score of lrm",lrm.score(x_test_n,y_test))
    print("Score of dtrm",dtrm.score(x_test_n,y_test))
    print("Score of svrm",Svrm.score(x_test_n,y_test))
    print("Score of rfrm",rfrm.score(x_test_n,y_test))

item=["MinMaxScaler","StandardScaler","PowerTransformer","QuantileTransformer"]
for scaler in item:
    print("By using"+scaler+"method")
    model_scale(scaler)

